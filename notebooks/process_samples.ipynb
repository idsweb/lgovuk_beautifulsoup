{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process all the sample files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the page content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install beautifulsoup4\n",
    "\n",
    "# Install the parsersc\n",
    "#!pip install html5lib\n",
    "#!pip install lxml\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import Comment, Tag, NavigableString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required modules for processing files\n",
    "import os\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the contents of the HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn a file into a bs4 object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_markup(filemane: str) :\n",
    "    with open(filemane) as fp:\n",
    "        noise_soup = BeautifulSoup(fp, 'html.parser')\n",
    "        return noise_soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update an attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_id(content: Tag, attribute: str, new_value: str):\n",
    "    id_attr = {}\n",
    "    id_attr[attribute] = new_value\n",
    "    content.attrs[attribute] = id_attr[attribute]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep only whitelisted CSS on elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be expanded to take in a JSON file or similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whitelist_css(content: Tag, whitelist: dict) :\n",
    "    for dirty_tag in content.select('[class]') :\n",
    "        clean_tags = []\n",
    "        for class_name in dirty_tag.attrs['class'] :\n",
    "            if( dirty_tag.name in whitelist):\n",
    "                if(class_name in whitelist[dirty_tag.name]) :\n",
    "                    clean_tags.append(class_name)\n",
    "        if(len(clean_tags) > 0) :\n",
    "            dirty_tag.attrs['class'] = clean_tags\n",
    "        else :\n",
    "            del(dirty_tag.attrs['class'])\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the accordian markup\n",
    "Flatten the old accordian markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_accordian(old_accordian: Tag) :\n",
    "    new_comment = Comment('Reformatted accordian')\n",
    "    old_accordian.insert(1,new_comment)\n",
    "\n",
    "    # Some accordians may have a button\n",
    "    button = old_accordian.find('button', class_=\"accordion__trigger\") #ToDo\n",
    "\n",
    "    # remove the class attributes or replace them\n",
    "    for h in old_accordian.find_all('h3') :\n",
    "        class_list = ['some_new_class']\n",
    "        class_attr = {}\n",
    "        class_attr['class'] = class_list\n",
    "        h.attrs = class_attr\n",
    "        #del(h.attrs['class'])\n",
    "    for div in old_accordian.find_all('div') :\n",
    "        div.unwrap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to find the page content from the soup\n",
    "\n",
    "This function takes a BeautifulSoup object and will find the page content based on its id attribute. For some reason this seems to need to be a two step process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_page_content(soup: BeautifulSoup) :\n",
    "\n",
    "    # Check if their is a H1 - if so grab the first one and then find the content div.\n",
    "    if type(soup.h1) == Tag :\n",
    "        outer = soup.h1.parent\n",
    "        content = outer.find('div', { 'id' : 'ctl00_PlaceHolderMain_ctl03__ControlWrapper_RichHtmlField'})\n",
    "        update_id(content, 'id', 'new_id')\n",
    "    else :\n",
    "        content = \"Missing\"\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through the directory and process the samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Master function to call smaller functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whitelist of CSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_to_keep = {}\n",
    "classes_to_keep['div'] = ['text-block','text']\n",
    "classes_to_keep['ol'] = ['list', 'list-step']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up function to process the old markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_html(soup) :\n",
    "    result = find_page_content(soup)\n",
    "\n",
    "    accordians = result.find_all('div', class_ = 'accordion')\n",
    "    if(len(accordians) > 0) :\n",
    "        for acc in accordians :\n",
    "            transform_accordian(acc)\n",
    "    result = whitelist_css(result, classes_to_keep)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the sample(s)\n",
    "\n",
    "Process the sample files and save a copy in the cleaned_pages folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snippet for generating sample pages\n",
    "\n",
    "new_file = '''\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Document</title>\n",
    "</head>\n",
    "<body>\n",
    "    \n",
    "</body>\n",
    "</html>\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to process each of the files in a list of filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and save the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import UnicodeDammit\n",
    "from pathlib import Path\n",
    " \n",
    "# iterate over files and process them through the clean up functions\n",
    "def clean_it(ugly_file: Path, ugly_file_directory: str, pretty_file_directory: str):\n",
    "\n",
    "    print('--------------------------------')\n",
    "    print('source:', ugly_file.resolve())\n",
    "\n",
    "    try :\n",
    "        # Detect the encoding\n",
    "        with open(ugly_file.resolve(), 'rb') as file:\n",
    "            content = file.read(1024)\n",
    "        suggestion = UnicodeDammit(content)\n",
    "        encoding = suggestion.original_encoding\n",
    "                \n",
    "        # load file into a string\n",
    "        ugly_soup_text = ugly_file.read_text(encoding=encoding)\n",
    "\n",
    "        # convert to a beautiful soup object\n",
    "        ugly_soup = BeautifulSoup(ugly_soup_text, 'html.parser')\n",
    "\n",
    "        # feed through the clean up process\n",
    "        pretty_soup = get_new_html(ugly_soup)\n",
    "\n",
    "        # for logging load the HTML wrapper\n",
    "        wrapper_soup = BeautifulSoup(new_file, 'html.parser')\n",
    "        wrapper_soup.body.insert(1, pretty_soup)\n",
    "\n",
    "        ugly_file_name = str(ugly_file.resolve())\n",
    "\n",
    "        new_path = ugly_file_name.replace(ugly_file_directory, pretty_file_directory)\n",
    "\n",
    "        pretty_file = Path(ugly_file_name.replace('test','cleaned_pages'))\n",
    "        print(pretty_file.resolve())\n",
    "\n",
    "        # create the files parents if they dont exist\n",
    "        pretty_file.parent.mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "        # save the file\n",
    "        if not pretty_file.exists() :\n",
    "            print('------ Saving file ---------')\n",
    "            pretty_file.write_text(wrapper_soup.prettify(), encoding=encoding)\n",
    "        else :\n",
    "            print('--------- File already exists -------------')\n",
    "\n",
    "    except Exception as ex: \n",
    "        print(f'something went wrong loading file {pretty_file.resolve()}', ex)\n",
    "        print('--------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate over the folder and process the files in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relative folder to save html source code.\n",
    "html_source_root_dir = Path(Path().parent) / '..' / 'test'\n",
    "\n",
    "# relative folder to save html source code.\n",
    "html_destination_root_dir = Path(Path().parent) / '..' / 'cleaned_pages'\n",
    "\n",
    "for src_html_file in html_source_root_dir.glob(\"**/*.html\") :\n",
    "    clean_it(src_html_file, str(html_source_root_dir.resolve()), str(html_destination_root_dir.resolve()) )\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
